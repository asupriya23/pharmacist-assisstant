{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1400106,"sourceType":"datasetVersion","datasetId":818027}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import TrOCRProcessor, VisionEncoderDecoderModel\nfrom PIL import Image\nimport requests\n\n# load image from the IAM database\nurl = '/kaggle/input/handwriting-recognition/train_v2/train/TRAIN_00001.jpg'\nimage = Image.open(url).convert(\"RGB\")\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T17:20:33.233761Z","iopub.execute_input":"2025-03-03T17:20:33.234037Z","iopub.status.idle":"2025-03-03T17:20:33.238878Z","shell.execute_reply.started":"2025-03-03T17:20:33.234016Z","shell.execute_reply":"2025-03-03T17:20:33.238226Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-handwritten')\nmodel = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-handwritten')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T17:20:37.037792Z","iopub.execute_input":"2025-03-03T17:20:37.038086Z","iopub.status.idle":"2025-03-03T17:21:05.752109Z","shell.execute_reply.started":"2025-03-03T17:20:37.038064Z","shell.execute_reply":"2025-03-03T17:21:05.751085Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7615d370a3641f1acb489587a127061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"550ca26393ec4eaba732bb8275193ead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d7ed1eb8ece49d4bd6022d86a642e15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6a366c5ad4c4ff9b95084f1b78d49e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37ede68333be41c69d877394c692f011"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.13k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e8c77df62c740f4b16996590b814653"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.23G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e2b8b7cb5964f00a05fea6c0c040be6"}},"metadata":{}},{"name":"stderr","text":"Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n  \"attention_probs_dropout_prob\": 0.0,\n  \"encoder_stride\": 16,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 1024,\n  \"image_size\": 384,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-12,\n  \"model_type\": \"vit\",\n  \"num_attention_heads\": 16,\n  \"num_channels\": 3,\n  \"num_hidden_layers\": 24,\n  \"patch_size\": 16,\n  \"qkv_bias\": false,\n  \"transformers_version\": \"4.47.0\"\n}\n\nConfig of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_cross_attention\": true,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": 0.0,\n  \"cross_attention_hidden_size\": 1024,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 12,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"eos_token_id\": 2,\n  \"init_std\": 0.02,\n  \"is_decoder\": true,\n  \"layernorm_embedding\": true,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"trocr\",\n  \"pad_token_id\": 1,\n  \"scale_embedding\": false,\n  \"transformers_version\": \"4.47.0\",\n  \"use_cache\": false,\n  \"use_learned_position_embeddings\": true,\n  \"vocab_size\": 50265\n}\n\nSome weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dba92296acf47cc8e31c7b62e8d6eba"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n\ngenerated_ids = model.generate(pixel_values)\ngenerated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T17:21:31.372819Z","iopub.execute_input":"2025-03-03T17:21:31.373176Z","iopub.status.idle":"2025-03-03T17:21:33.832318Z","shell.execute_reply.started":"2025-03-03T17:21:31.373116Z","shell.execute_reply":"2025-03-03T17:21:33.831366Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"generated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T17:23:02.647263Z","iopub.execute_input":"2025-03-03T17:23:02.647574Z","iopub.status.idle":"2025-03-03T17:23:02.653245Z","shell.execute_reply.started":"2025-03-03T17:23:02.647554Z","shell.execute_reply":"2025-03-03T17:23:02.652226Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'Balthazar'"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}